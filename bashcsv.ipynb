{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV command-line kung fu\n",
    "\n",
    "You might be surprised how much data slicing and dicing you can do from the command line using some simple tools and I/O redirection + piping. (See [A Quick Introduction to Pipes and Redirection](http://bconnelly.net/working-with-csvs-on-the-command-line/#a-quick-introduction-to-pipes-and-redirection)). We've already seen I/O redirection where we took the output of a command and wrote it to a file (`/tmp/t.csv`):\n",
    " \n",
    "```bash\n",
    "$ iconv -c -f utf-8 -t ascii SampleSuperstoreSales.csv > /tmp/t.csv\n",
    "```\n",
    "\n",
    "## Set up\n",
    "\n",
    "```bash\n",
    "pip install csvkit\n",
    "```\n",
    "\n",
    "## Extracting rows with grep\n",
    "\n",
    "Now, let me introduce you to the `grep` command that lets us filter the lines in a file according to a regular expression. Here's how to find all rows that contain `Annie Cyprus`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249,1702,5/6/11,High,23,67.24,0.06,Regular Air,4.90,2.84,0.93,Annie Cyprus,Nunavut,Nunavut,Home Office,Office Supplies,Pens & Art Supplies,SANFORD Liquid Accent� Tank-Style Highlighters,Wrap Bag,0.54,5/7/11\r\n",
      "669,4676,8/31/11,High,11,1210.0515,0.04,Regular Air,-104.25,125.99,7.69,Annie Cyprus,Nunavut,Nunavut,Home Office,Technology,Telephones and Communication,Timeport L7089,Small Box,0.58,9/1/11\r\n",
      "670,4676,8/31/11,High,50,187.83,0.03,Regular Air,85.96,3.75,0.5,Annie Cyprus,Nunavut,Nunavut,Home Office,Office Supplies,Labels,Avery 510,Small Box,0.37,9/2/11\r\n"
     ]
    }
   ],
   "source": [
    "! grep 'Annie Cyprus' data/SampleSuperstoreSales.csv | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't have to write any code. We didn't have to jump into a development environment or editor. We just asked for the sales for Annie. If we want to write the data to a file, we simply redirect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249,1702,5/6/11,High,23,67.24,0.06,Regular Air,4.90,2.84,0.93,Annie Cyprus,Nunavut,Nunavut,Home Office,Office Supplies,Pens & Art Supplies,SANFORD Liquid Accent� Tank-Style Highlighters,Wrap Bag,0.54,5/7/11\r\n",
      "669,4676,8/31/11,High,11,1210.0515,0.04,Regular Air,-104.25,125.99,7.69,Annie Cyprus,Nunavut,Nunavut,Home Office,Technology,Telephones and Communication,Timeport L7089,Small Box,0.58,9/1/11\r\n",
      "670,4676,8/31/11,High,50,187.83,0.03,Regular Air,85.96,3.75,0.5,Annie Cyprus,Nunavut,Nunavut,Home Office,Office Supplies,Labels,Avery 510,Small Box,0.37,9/2/11\r\n"
     ]
    }
   ],
   "source": [
    "! grep 'Annie Cyprus' data/SampleSuperstoreSales.csv > /tmp/Annie.csv\n",
    "! head -3 /tmp/Annie.csv # show first 3 lines of that new file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering with csvgrep\n",
    "\n",
    "[csvkit](https://csvkit.readthedocs.io/en/1.0.3/) is an amazing package with lots of cool CSV utilities for use on the command line. `csvgrep` is one of them.\n",
    "\n",
    "If we want a specific row ID, then we need to use the more powerful `csvgrep` not just `grep`. We use a different regular expression that looks for a specific string at the left edge of a line (`^` means the beginning of a line, `$` means end of line or end of record):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID,Order ID,Order Date,Order Priority,Order Quantity,Sales,Discount,Ship Mode,Profit,Unit Price,Shipping Cost,Customer Name,Province,Region,Customer Segment,Product Category,Product Sub-Category,Product Name,Product Container,Product Base Margin,Ship Date\r\n",
      "80,483,7/10/11,High,30,4965.7595,0.08,Regular Air,1198.97,195.99,3.99,Clay Rozendal,Nunavut,Nunavut,Corporate,Technology,Telephones and Communication,R380,Small Box,0.58,7/12/11\r\n"
     ]
    }
   ],
   "source": [
    "! csvgrep -c 1 -r '^80$' -e latin1 data/SampleSuperstoreSales.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want, say, two different rows added to another file?  We do two `grep`s and a `>>` concatenation redirection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID,Order ID,Order Date,Order Priority,Order Quantity,Sales,Discount,Ship Mode,Profit,Unit Price,Shipping Cost,Customer Name,Province,Region,Customer Segment,Product Category,Product Sub-Category,Product Name,Product Container,Product Base Margin,Ship Date\r\n",
      "80,483,7/10/11,High,30,4965.7595,0.08,Regular Air,1198.97,195.99,3.99,Clay Rozendal,Nunavut,Nunavut,Corporate,Technology,Telephones and Communication,R380,Small Box,0.58,7/12/11\r\n",
      "Row ID,Order ID,Order Date,Order Priority,Order Quantity,Sales,Discount,Ship Mode,Profit,Unit Price,Shipping Cost,Customer Name,Province,Region,Customer Segment,Product Category,Product Sub-Category,Product Name,Product Container,Product Base Margin,Ship Date\r\n",
      "160,995,5/30/11,Medium,46,1815.49,0.03,Regular Air,782.91,39.89,3.04,Neola Schneider,Nunavut,Nunavut,Home Office,Furniture,Office Furnishings,Ultra Commercial Grade Dual Valve Door Closer,Wrap Bag,0.53,5/31/11\r\n"
     ]
    }
   ],
   "source": [
    "! csvgrep -c 1 -r '^80$' -e latin1 data/SampleSuperstoreSales.csv > /tmp/two.csv # write first row\n",
    "! csvgrep -c 1 -r '^160$' -e latin1 data/SampleSuperstoreSales.csv >> /tmp/two.csv # append second row\n",
    "! cat /tmp/two.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning, end of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we'd like to see just the header row, we can use `head`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID,Order ID,Order Date,Order Priority,Order Quantity,Sales,Discount,Ship Mode,Profit,Unit Price,Shipping Cost,Customer Name,Province,Region,Customer Segment,Product Category,Product Sub-Category,Product Name,Product Container,Product Base Margin,Ship Date\r\n"
     ]
    }
   ],
   "source": [
    "! head -1 data/SampleSuperstoreSales.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, on the other hand, we want to see everything but that row, we can use `tail` (which I pipe to `head` so then I see only the first two lines of output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,3,10/13/10,Low,6,261.54,0.04,Regular Air,-213.25,38.94,35,Muhammed MacIntyre,Nunavut,Nunavut,Small Business,Office Supplies,Storage & Organization,\"Eldon Base for stackable storage shelf, platinum\",Large Box,0.8,10/20/10\r\n",
      "49,293,10/1/12,High,49,10123.02,0.07,Delivery Truck,457.81,208.16,68.02,Barry French,Nunavut,Nunavut,Consumer,Office Supplies,Appliances,\"1.7 Cubic Foot Compact \"\"Cube\"\" Office Refrigerators\",Jumbo Drum,0.58,10/2/12\r\n",
      "tail: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "! tail +2 data/SampleSuperstoreSales.csv | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output would normally be many thousands of lines here so I have *piped* the output to the `head` command to print just the first two rows.  We can pipe many commands together, sending the output of one command as input to the next command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Count how many sales items there are in the `Technology` product category that are also `High` order priorities? Hint: `wc -l` counts the number of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     449\r\n"
     ]
    }
   ],
   "source": [
    "! grep Technology, data/SampleSuperstoreSales.csv | grep High, | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extracting columns with csvcut\n",
    "\n",
    "Extracting columns is also pretty easy with `csvcut`. For example, let's say we wanted to get the customer name column (which is 12th by my count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Name\r\n",
      "Muhammed MacIntyre\r\n",
      "Barry French\r\n",
      "Barry French\r\n",
      "Clay Rozendal\r\n",
      "Carlos Soltero\r\n",
      "Carlos Soltero\r\n",
      "Carl Jackson\r\n",
      "Carl Jackson\r\n",
      "Monica Federle\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 12 -e latin1 data/SampleSuperstoreSales.csv | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, hang on a second. We don't want the `Customer Name` header to appear in the list so we combine with the `tail` we just saw to strip the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammed MacIntyre\r\n",
      "Barry French\r\n",
      "Barry French\r\n",
      "Clay Rozendal\r\n",
      "Carlos Soltero\r\n",
      "Carlos Soltero\r\n",
      "Carl Jackson\r\n",
      "Carl Jackson\r\n",
      "Monica Federle\r\n",
      "Dorothy Badders\r\n",
      "tail: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 12 -e latin1 data/SampleSuperstoreSales.csv | tail +2 | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want a unique list? All we have to do is sort and then call `uniq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron Bergman\r\n",
      "Aaron Hawkins\r\n",
      "Aaron Smayling\r\n",
      "Adam Bellavance\r\n",
      "Adam Hart\r\n",
      "Adam Shillingsburg\r\n",
      "Adrian Barton\r\n",
      "Adrian Hane\r\n",
      "Adrian Shami\r\n",
      "Aimee Bixby\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 12 -e latin1 data/SampleSuperstoreSales.csv | tail +2 | sort | uniq | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get multiple columns at once in the order specified. For example, here is how to get the sales ID and the customer name together (name first then ID):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Name,Order ID\r\n",
      "Muhammed MacIntyre,3\r\n",
      "Barry French,293\r\n",
      "Barry French,293\r\n",
      "Clay Rozendal,483\r\n",
      "Carlos Soltero,515\r\n",
      "Carlos Soltero,515\r\n",
      "Carl Jackson,613\r\n",
      "Carl Jackson,613\r\n",
      "Monica Federle,643\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 12,2 -e latin1 data/SampleSuperstoreSales.csv |head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we can write any of this output to a file using the `>` redirection operator. Let's do that and put each of those columns into a separate file and then `paste` them back with the customer name first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Name\tOrder ID\r\n",
      "Muhammed MacIntyre\t3\r\n",
      "Barry French\t293\r\n",
      "Barry French\t293\r\n",
      "Clay Rozendal\t483\r\n",
      "Carlos Soltero\t515\r\n",
      "Carlos Soltero\t515\r\n",
      "Carl Jackson\t613\r\n",
      "Carl Jackson\t613\r\n",
      "Monica Federle\t643\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 2 -e latin1 data/SampleSuperstoreSales.csv > /tmp/IDs\n",
    "! csvcut -c 12 -e latin1 data/SampleSuperstoreSales.csv > /tmp/names\n",
    "! paste /tmp/names /tmp/IDs | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing, right?! This is often a very efficient means of manipulating data files because you are directly talking to the operating system instead of through Python libraries. We also don't have to write any code, we just have to know some syntax for terminal commands.\n",
    "\n",
    "Not impressed yet? Ok, how about creating a histogram indicating the number of sales per customer sorted in reverse numerical order? We've already got the list of customers and we can use an argument on `uniq` to get the count instead of just making a unique set. Then, we can use a second `sort` with arguments to reverse sort and use numeric rather than text-based sorting. This gives us a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  41 Darren Budd\r\n",
      "  38 Ed Braxton\r\n",
      "  35 Brad Thomas\r\n",
      "  33 Carlos Soltero\r\n",
      "  30 Patrick Jones\r\n",
      "  29 Tony Sayre\r\n",
      "  28 Nora Price\r\n",
      "  28 Mark Cousins\r\n",
      "  28 Lena Creighton\r\n",
      "  28 Joy Smith\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 12 -e latin1 data/SampleSuperstoreSales.csv | tail +2 | sort | uniq -c | sort -r -n | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Modify the command so that you get a histogram of the shipping mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6270 Regular Air\r\n",
      "1146 Delivery Truck\r\n",
      " 983 Express Air\r\n"
     ]
    }
   ],
   "source": [
    "! csvcut -c 8 -e latin1 data/SampleSuperstoreSales.csv | tail +2 | sort | uniq -c | sort -r -n | head -10"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "103px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
